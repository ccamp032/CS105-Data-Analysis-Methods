{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fIkB7OAmFGYX"
   },
   "source": [
    "# Time Series Data (optional lab)\n",
    "\n",
    "A _time series_ is simply a series of measurements indexed by time. We will discuss strategies for analyzing and visualizing time series data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T_B5ltlGFGYb"
   },
   "source": [
    "# Working with Time Series Data\n",
    "\n",
    "In this lesson, we will work with [a data set from the National Oceanic & Atmospheric Administration (NOAA)](http://www.esrl.noaa.gov/gmd/ccgg/trends/) consisting of weekly measurements of atmospheric carbon dioxide ($\\text{CO}_2$) at the Mauna Loa Observatory in Hawaii, dating back to 1974. Since atmospheric $\\text{CO}_2$ is considered to be one of the primary drivers of climate change, this time series is highly relevant to climate policy.\n",
    "\n",
    "First, let's read in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O8t64e2-FGYc"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_co2 = pd.read_csv(\"mauna_loa_co2_weekly.csv\")\n",
    "df_co2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mKCMrnZdFGYg"
   },
   "source": [
    "By default, the dates are stored as strings. In order to make `pandas` recognize them as dates, we call `pd.to_datetime`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_xBxlcKUFGYh"
   },
   "outputs": [],
   "source": [
    "pd.to_datetime(df_co2[\"date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4EUrgfFMFGYl"
   },
   "source": [
    "Notice that the `dtype` of this `Series` is `datetime64[ns]`, which is a special type for storing dates and times. \n",
    "\n",
    "In this particular example, `pandas` was able to automatically infer the correct formatting of the dates; however, we can also specify the format explicitly, using the [standard format codes](https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-ctQgSHBFGYm"
   },
   "outputs": [],
   "source": [
    "pd.to_datetime(df_co2[\"date\"], format=\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xe1Rtr1hFGYp"
   },
   "source": [
    "It makes sense to make the date the index of this `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M_lSoRqhFGYq"
   },
   "outputs": [],
   "source": [
    "df_co2.index = pd.to_datetime(df_co2[\"date\"], format=\"%Y-%m-%d\")\n",
    "df_co2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "puytsxXeFGYt"
   },
   "source": [
    "Another way to achieve (essentially) the same result is to read in the **date** column as the index and to specify that the values should be parsed as dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hz0S0_4mFGYv"
   },
   "outputs": [],
   "source": [
    "pd.read_csv(data_dir + \"mauna_loa_co2_weekly.csv\",\n",
    "            index_col=\"date\",\n",
    "            parse_dates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LmBqG_9EFGY2"
   },
   "source": [
    "## Visualizing Time Series\n",
    "\n",
    "Time series are typically plotted as a line, with time on the $x$-axis and the measurement on the $y$-axis. Since our `DataFrame` is already indexed by time, we can simply select the variable we want to plot (**ppm**, the concentration of $\\text{CO}_2$ in parts per million) and call `.plot.line()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6RDc_Fo-FGY3"
   },
   "outputs": [],
   "source": [
    "df_co2[\"ppm\"].plot.line()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cIWwHP0HFGY5"
   },
   "source": [
    "Oops! It seems that there are some missing values in the data that are coded as $-999.99$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pS1uAWuXFGY6"
   },
   "outputs": [],
   "source": [
    "df_co2[df_co2[\"ppm\"] < 0][\"ppm\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "McyUKM0zFGY9"
   },
   "source": [
    "Let's replace these values with `NaN`s and recreate the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a9iDPjV1FGY-"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df_co2 = df_co2.replace(-999.99, np.nan)\n",
    "ppm = df_co2[\"ppm\"]\n",
    "ppm.plot.line()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2eqcjtYkFGZA"
   },
   "source": [
    "The upward trend in this graph has been cause of great consternation.\n",
    "\n",
    "Let's take a closer look at what `pandas` did with those missing values that we filtered out. We saw above that measurements were missing for all 4 weeks in December 1975. Let's zoom in on this region by restricting to dates before February 1976. We can compare use logical operators (`<`, `>`, `==`, etc.) to compare dates, except that we have to be sure to compare dates with dates, creating `datetime` objects as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UbFjUm_dFGZB"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "(ppm[ppm.index < datetime(1976, 2, 1)].\n",
    " plot.line(style=\"o-\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DPN7BhOnFGZE"
   },
   "source": [
    "Notice how `pandas` left the appropriate space between the measurement on 1975-11-30 and the next available measurement on 1976-01-04. This is one advantage of casting dates to `datetime`s, rather than simply leaving them as strings. If we had instead made a line plot using the **date** column (which stores the dates as strings), then the values would still have been plotted in the right order, but the points would be uniformly spaced, instead of spaced according to how far apart they are in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K99jtn4xFGZE"
   },
   "outputs": [],
   "source": [
    "df_co2_no_na = df_co2.dropna()\n",
    "\n",
    "(df_co2_no_na[df_co2_no_na.index < datetime(1976, 2, 1)].\n",
    " plot.line(x=\"date\", y=\"ppm\", style=\"o-\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nx2sBWoyFGZH"
   },
   "source": [
    "## Changing the Sampling Frequency\n",
    "\n",
    "From the graph, there is a clear seasonal pattern in $\\text{CO}_2$ levels. The levels increase in the winter (in the northern hemisphere), peaking around May of each year, and then decline in the summer. Plants are responsible for this seasonal pattern. In the summer months, plants absorb $\\text{CO}_2$ from the atmosphere as part of photosynthesis, in order to grow flowers and leaves. In the winter months, these leaves fall to the ground, where they are broken down by microbes that emit $\\text{CO}_2$ in the process. \n",
    "\n",
    "However, these seasonal fluctuations are dwarfed by the overall increasing trend, which is thought to be caused by human activities. To see the overall trend more clearly, we can calculate the yearly average, therefore smoothing over all of the seasonal fluctuations. Although this can be done manually, `pandas` provides a convenience method, `.resample()`, that changes the sampling frequency of the time series. The `.resample()` function works like `.groupby()`; you have to specify a column and an aggregation function. In the code below, we average the **ppm** in each year to obtain a time series with a sampling frequency of 1 year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2dQoZNVIFGZI"
   },
   "outputs": [],
   "source": [
    "ppm_1y = df_co2.resample(\"1Y\")[\"ppm\"].mean()\n",
    "ppm_1y.plot.line()\n",
    "ppm_1y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_-9YcweFFGZM"
   },
   "source": [
    "## Lags and Differences\n",
    "\n",
    "Another way to remove the effect of seasonality is to take differences. If we take each measurement and subtract the measurement from a year earlier, then any seasonal effect should cancel out, since we are comparing winter measurements to winter measurements and summer measurements to summer measurements.\n",
    "\n",
    "The easiest way to take this difference is to shift (or _lag_) all of the values in the `DataFrame`. Since each row in our `DataFrame` represents 1 week, we should shift the `DataFrame` by 52 rows so that every value is lined up with its value 1 year ago."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4IkCDDfJFGZM"
   },
   "outputs": [],
   "source": [
    "df_co2_lag = df_co2.shift(52)\n",
    "df_co2_lag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bn-sZw_qFGZV"
   },
   "source": [
    "By comparing the **date** index (which was not shifted) to the **date** column (which was shifted), we see that the values in the `DataFrame` correspond to approximately 1 year earlier than the date in the index. Therefore, if we subtract these lagged **ppm** values from the original **ppm** values, we obtain a `Series` of one-year changes in **ppm**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4rT44qKqFGZW"
   },
   "outputs": [],
   "source": [
    "diffs = df_co2[\"ppm\"] - df_co2_lag[\"ppm\"]\n",
    "diffs.plot.line()\n",
    "diffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "91CMYvmEFGZc"
   },
   "source": [
    "The seasonality is gone, but so is the trend. The fact that these differences hover around 1.5 tells us that **ppm** has been increasing by about 1.5 ppm per year.\n",
    "\n",
    "In accounting, these types of metrics are called \"Year-over-Year\" (YoY) metrics. They are valuable precisely because they eliminate the seasonal effects that are common in many industries (e.g., holiday season for retail businesses)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w4R0CC3JFGZd"
   },
   "source": [
    "## Exercises\n",
    "\n",
    "Exercises 1-2 ask you to work with the Austin weather data set (austin_weather_2019.csv ), which contains hourly measurements of the weather in Austin, TX in 2019. This data set was collected from the [NOAA](https://www.ncdc.noaa.gov/crn/qcdatasets.html). See the [data documentation](https://www1.ncdc.noaa.gov/pub/data/uscrn/products/hourly02/README.txt) for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s3OiF3tnFGZe"
   },
   "source": [
    "1\\. Read in the data set. Plot the hourly temperature (**T_HR_AVG**) time series as a function of the local date and time (**LST_DATE**, **LST_TIME**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6wbLPI28FGZe"
   },
   "source": [
    "2\\. The hourly temperature plot is extremely noisy. Plot the daily average temperature and weekly average temperature to get a better sense of the climate in Austin, TX."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "8.1 Working with Time Series Data.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
